{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56103802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64e554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NavigableString is a type in BeautifulSoup. It is similar to strings but are not strings.\n",
    "# This function converts each NavigableString of the input list to string\n",
    "def concatenate_NavigableString(NS_list):\n",
    "    result = ''\n",
    "    for NS in NS_list:\n",
    "        result = result + str(NS)\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13eb4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = 'book/' \n",
    "book_file = 'abacaxi.html' \n",
    "full_name = path + book_file \n",
    "doc = open(full_name,'r') \n",
    "html_doc = doc.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e310b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo carregado com sucesso: book/abacaxi.html\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = 'book/'  \n",
    "book_file = 'abacaxi.html'\n",
    "\n",
    "full_name = path + book_file\n",
    "with open(full_name, 'r', encoding='utf-8') as doc:\n",
    "    html_doc = doc.read()\n",
    "\n",
    "print(\"Arquivo carregado com sucesso:\", full_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed39e4fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "tuple_list = []\n",
    "book = soup.title.string\n",
    "\n",
    "# Head attributes\n",
    "list_meta = soup.find_all(\"meta\")\n",
    "list_link = soup.find_all(\"link\")\n",
    "\n",
    "for meta_data in list_meta:\n",
    "    if meta_data.get(\"name\", None) == \"epub\":\n",
    "        epub = meta_data.get(\"content\", None)\n",
    "    elif meta_data.get(\"name\", None) == \"pdf\":\n",
    "        pdf = meta_data.get(\"content\", None)\n",
    "    elif meta_data.get(\"name\", None) == \"identifier\":\n",
    "        identifier = meta_data.get(\"content\", None)\n",
    "    elif meta_data.get(\"name\", None) == \"year\":\n",
    "        year = meta_data.get(\"content\", None)\n",
    "\n",
    "for link_data in list_link:\n",
    "    if \"license\" in link_data.get(\"rel\", None):  # rel is string list\n",
    "        license = link_data.get(\"href\", None)\n",
    "        \n",
    "pre_body = soup.body  # It can contain empty lines\n",
    "\n",
    "body = []\n",
    "\n",
    "# Remove empty lines or lines with ' ', \\t, ou \\n\n",
    "for element in pre_body:\n",
    "    line = str(element).strip()\n",
    "    if len(line) > 0:\n",
    "        body.append(element)\n",
    "\n",
    "resposta = \"\"\n",
    "capitulo = \"\"\n",
    "\n",
    "for element in body:\n",
    "\n",
    "    ## --- Tag h1 ---\n",
    "    if element.name == \"h1\":\n",
    "        capitulo = str(element.string)\n",
    "    \n",
    "    ## --- Tag p ---\n",
    "    elif element.name == \"p\":    \n",
    "        if \"class\" in element.attrs:\n",
    "            \n",
    "            tag_class = element[\"class\"]   # class = \"separador\"; or there is no class in <p>\n",
    "            \n",
    "            ## --- <p class=\"separador\"> --\n",
    "            if \"separador\" in tag_class:\n",
    "                tuple_list.append((identifier, book, nro_pergunta, capitulo, pergunta, resposta))\n",
    "                resposta = \"\"\n",
    "                \n",
    "            ## --- <p class=\"pergunta\"> --\n",
    "            elif \"pergunta\" in tag_class:\n",
    "                \n",
    "                pergunta_inteira = concatenate_NavigableString(element.contents)\n",
    "\n",
    "                pergunta_inteira = pergunta_inteira.replace('\\n',' ')\n",
    "                # It is important to remove \\n from question so it does not cause errors in pattern match (re.search)\n",
    "                # For answer there is not this kind of match. So it can be done after this function\n",
    "                # in answer processing with 'process_text' for bulk file generation\n",
    "                \n",
    "                q = re.search('^ *([0-9]+) *\\) *(.*)', pergunta_inteira)   \n",
    "                # '^ *([0-9]+) *\\) *'\n",
    "                # '^ *'  =  string begins ('^') with zero or more blanks (' *') => '^ *'\n",
    "                # After, it comes a natural number [0-9]+ with one or more ('+') digits  =>  '[0-9]+'\n",
    "                # Parenthesis indicates a group, the first group   =>  '([0-9]+)'\n",
    "                # group(0) gets all the matched string\n",
    "                # group(1) gets the first group '([0-9]+)', the natural number\n",
    "                # group(2) gets what comes inside the second parenthesis: (.*)\n",
    "                # After the natural number, there are zero ou more blanks => ' *'\n",
    "                # Then, the character ')' . It needs the scape char '\\'  =>  '\\)' \n",
    "                # Again zero ou more blanks => ' *'\n",
    "                # Then the second group, which represents the question text with 0 ou more characters => '(.*)'\n",
    "                \n",
    "                nro_pergunta = int(q.group(1))  # ([0-9]+)\n",
    "                pergunta = q.group(2)           # (.*) \n",
    "                \n",
    "            ## --- <p> with class, but not \"separador\" or \"pergunta\" ---\n",
    "            else: # it is <p> but it is not a question and it is not separator => it is answer\n",
    "                content = '<p>' + concatenate_NavigableString(element.contents) + '</p>'\n",
    "                resposta = resposta + content\n",
    "        \n",
    "        ## --- <p> without class ---\n",
    "        else: # it is <p> but it is not a question and it is not separator => it is answer\n",
    "            content = '<p>' + concatenate_NavigableString(element.contents) + '</p>'\n",
    "            resposta = resposta + content\n",
    "           \n",
    "    ## --- Outras tags ---\n",
    "    else:\n",
    "        content = str(element)\n",
    "        resposta = resposta + content\n",
    "        \n",
    "    ## Other tags are ignored. e.g. div\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ece181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    return text.replace('\"','\\\\\"').replace('\\n','')\n",
    "    # scape char \" with \\\"\n",
    "    # there is no newline for bulk text generation\n",
    "\n",
    "questions_checking = np.zeros(500)  \n",
    "\n",
    "# format of the output file name\n",
    "outFileName = path + 'bulk-' + identifier + \".txt\"  \n",
    "outFile = open(outFileName, 'w')\n",
    "\n",
    "\n",
    "index_name = \"my-index-000001\"\n",
    "\n",
    "for tuple in tuple_list:\n",
    "    identifier, book, question_number, chapter, question, answer = tuple\n",
    "    ## The string number of the question has three chars: 001, 002, ..., 500\n",
    "    key = identifier + '_' + '{:03d}'.format(question_number)  \n",
    "    questions_checking[question_number-1] = 1\n",
    "    \n",
    "\n",
    "    ## writing in output file \n",
    "    print(\"{\\\"index\\\":{\\\"_id\\\": \\\"\" + key  + \"\\\"}}\", file = outFile)\n",
    "    print(\"{\\\"question_number\\\": \" + str(question_number) + \", \\\"question\\\":\\\"\" + process_text(question) + \"\\\", \\\"answer\\\":\" +\n",
    "          \"\\\"\" + process_text(answer) + \"\\\", \\\"chapter\\\": \\\"\" + process_text(chapter) + \"\\\", \\\"book\\\": \\\"\" + process_text(book) + \n",
    "          \"\\\", \\\"book_id\\\": \\\"\" + identifier + \"\\\", \\\"epub\\\": \\\"\" + epub + \"\\\", \\\"pdf\\\": \\\"\" + pdf + \"\\\", \\\"year\\\": \" + year +          \n",
    "          \"}\", file = outFile)    \n",
    "    \n",
    "outFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15eaa1aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,500):\n",
    "    if questions_checking[i]==0:\n",
    "        print(\"Not added question: \",i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8bc6d",
   "metadata": {},
   "source": [
    "The generated bulk file can be used to index the content in Elasticsearch with curl command as in:\n",
    "\n",
    "curl -H \"Content-Type:application/x-ndjson\" -XPOST \"http://localhost:9200/my-index/_bulk?pretty\" --data-binary @\"bulk-algodao.txt\"\n",
    "\n",
    "content-type is x-ndjson: json objects separated by newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29eb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
